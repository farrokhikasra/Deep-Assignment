{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d0ad9d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import SVHN, MNIST\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "feature_model = nn.Sequential(nn.Conv2d(1, 32, 5), nn.BatchNorm2d(32), nn.ReLU(), \n",
    "                      nn.MaxPool2d(2, stride=2),\n",
    "                      nn.Conv2d(32, 64, 5), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                      nn.Conv2d(64, 64, 3), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                      nn.AdaptiveAvgPool2d((1,1)), nn.Flatten())\n",
    "\n",
    "# For (b)-(c) add the task heads on top of the feature_model\n",
    "# Note this model can adapt the averaging to the size so inputs of 32x32 and 28x28 both work\n",
    "# Grayscale conversion for SVHN, you may use transforms.Grayscale(num_output_channels=1) found in torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e4fa1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize train and test datasets\n",
    "train_set = MNIST('../data',\n",
    "                           train=True,\n",
    "                           download=True,\n",
    "                           transform=transforms.ToTensor())\n",
    "test_set = MNIST('../data',\n",
    "                          train=False,\n",
    "                          download=True,\n",
    "                          transform=transforms.ToTensor())\n",
    "\n",
    "# Initialize train and test data loaders\n",
    "train_mnist = torch.utils.data.DataLoader(train_set,\n",
    "                                           batch_size=256,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)\n",
    "test_mnist = torch.utils.data.DataLoader(test_set,\n",
    "                                          batch_size=256,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd3cd237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ..data/train_32x32.mat\n",
      "Using downloaded and verified file: ..data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "train_set1 = SVHN(root='..data/', download=True, split='train',\n",
    "                   transform=torchvision.transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test_set1 = SVHN(root='..data/', download=True, split='test',\n",
    "                   transform=torchvision.transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "train_svhn = torch.utils.data.DataLoader(train_set1, \n",
    "                                           batch_size=256,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)\n",
    "test_svhn = torch.utils.data.DataLoader(test_set1,\n",
    "                                          batch_size=256,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71b7d5dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## MNIST model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model_mnist \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBatchNorm2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReLU\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#For (e) use SVHN nn.Conv2d(3,32,5)\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMaxPool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBatchNorm2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReLU\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBatchNorm2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReLU\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdaptiveAvgPool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFlatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_zoo\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrderedDict\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py:907\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 601\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/cuda/__init__.py:210\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "## MNIST model\n",
    "model_mnist = nn.Sequential(nn.Conv2d(1, 32, 5), nn.BatchNorm2d(32), nn.ReLU(), #For (e) use SVHN nn.Conv2d(3,32,5)\n",
    "                      nn.MaxPool2d(2, stride=2),\n",
    "                      nn.Conv2d(32, 64, 5), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                      nn.Conv2d(64, 64, 3), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                      nn.AdaptiveAvgPool2d((1,1)), nn.Flatten()).to(device)\n",
    "\n",
    "from torch.utils import model_zoo\n",
    "from collections import OrderedDict\n",
    "### SVHN model, we will download one that is already trained to clasify svhn digits\n",
    "model_urls = {\n",
    "    'svhn': 'http://ml.cs.tsinghua.edu.cn/~chenxi/pytorch-models/svhn-f564f3d8.pth',\n",
    "}\n",
    "\n",
    "class SVHN(nn.Module):\n",
    "    def __init__(self, features, n_channel, num_classes):\n",
    "        super(SVHN, self).__init__()\n",
    "        assert isinstance(features, nn.Sequential), type(features)\n",
    "        self.features = features\n",
    "\n",
    "        #We won't use this classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(n_channel, num_classes)\n",
    "        )\n",
    "        print(self.features)\n",
    "        print(self.classifier)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for i, v in enumerate(cfg):\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            padding = v[1] if isinstance(v, tuple) else 1\n",
    "            out_channels = v[0] if isinstance(v, tuple) else v\n",
    "            conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=padding)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(out_channels, affine=False), nn.ReLU(), nn.Dropout(0.3)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(), nn.Dropout(0.3)]\n",
    "            in_channels = out_channels\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def svhn_model(n_channel, pretrained=None):\n",
    "    cfg = [n_channel, n_channel, 'M', 2*n_channel, 2*n_channel, 'M', 4*n_channel, 4*n_channel, 'M', (8*n_channel, 0), 'M']\n",
    "    layers = make_layers(cfg, batch_norm=True)\n",
    "    model = SVHN(layers, n_channel=8*n_channel, num_classes=10)\n",
    "    if pretrained is not None:\n",
    "        m = model_zoo.load_url(model_urls['svhn'])\n",
    "        state_dict = m.state_dict() if isinstance(m, nn.Module) else m\n",
    "        assert isinstance(state_dict, (dict, OrderedDict)), type(state_dict)\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "base_svhn = svhn_model(n_channel=32,pretrained=True).features\n",
    "svhn_to_joint = nn.Linear(256,64)\n",
    "\n",
    "model_svhn = nn.Sequential(base_svhn, nn.AdaptiveAvgPool2d((1,1)), nn.Flatten(), svhn_to_joint).to(device)\n",
    "\n",
    "\n",
    "#Transformation for SVHN data, you need to use this normalization for the pre-trained model to work properly \n",
    "transform=transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a694ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(list(model_mnist.parameters()) + list(svhn_to_joint.parameters()), lr=1e-5) # you may experiment with different learning rates\n",
    "model_svhn.eval() #IMPORTANT: BEFORE running set to eval even for training to avoid dropout, we want to keep this fixed except the final layer, otherwise training will need to be much longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c7cafac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7286, grad_fn=<AddBackward0>)\n",
      "tensor(0.7918, grad_fn=<AddBackward0>)\n",
      "tensor(0.7297, grad_fn=<AddBackward0>)\n",
      "tensor(0.8100, grad_fn=<AddBackward0>)\n",
      "tensor(0.7213, grad_fn=<AddBackward0>)\n",
      "tensor(0.7424, grad_fn=<AddBackward0>)\n",
      "tensor(0.6885, grad_fn=<AddBackward0>)\n",
      "tensor(0.8171, grad_fn=<AddBackward0>)\n",
      "tensor(0.7682, grad_fn=<AddBackward0>)\n",
      "tensor(0.7129, grad_fn=<AddBackward0>)\n",
      "tensor(0.7642, grad_fn=<AddBackward0>)\n",
      "tensor(0.7573, grad_fn=<AddBackward0>)\n",
      "tensor(0.7544, grad_fn=<AddBackward0>)\n",
      "tensor(0.7109, grad_fn=<AddBackward0>)\n",
      "tensor(0.7202, grad_fn=<AddBackward0>)\n",
      "tensor(0.7303, grad_fn=<AddBackward0>)\n",
      "tensor(0.6877, grad_fn=<AddBackward0>)\n",
      "tensor(0.6700, grad_fn=<AddBackward0>)\n",
      "tensor(0.7086, grad_fn=<AddBackward0>)\n",
      "tensor(0.6675, grad_fn=<AddBackward0>)\n",
      "tensor(0.6926, grad_fn=<AddBackward0>)\n",
      "tensor(0.6707, grad_fn=<AddBackward0>)\n",
      "tensor(0.6863, grad_fn=<AddBackward0>)\n",
      "tensor(0.6630, grad_fn=<AddBackward0>)\n",
      "tensor(0.7164, grad_fn=<AddBackward0>)\n",
      "tensor(0.6780, grad_fn=<AddBackward0>)\n",
      "tensor(0.5852, grad_fn=<AddBackward0>)\n",
      "tensor(0.6688, grad_fn=<AddBackward0>)\n",
      "tensor(0.5794, grad_fn=<AddBackward0>)\n",
      "tensor(0.6850, grad_fn=<AddBackward0>)\n",
      "tensor(0.6861, grad_fn=<AddBackward0>)\n",
      "tensor(0.6075, grad_fn=<AddBackward0>)\n",
      "tensor(0.6689, grad_fn=<AddBackward0>)\n",
      "tensor(0.6796, grad_fn=<AddBackward0>)\n",
      "tensor(0.5740, grad_fn=<AddBackward0>)\n",
      "tensor(0.5820, grad_fn=<AddBackward0>)\n",
      "tensor(0.6815, grad_fn=<AddBackward0>)\n",
      "tensor(0.5827, grad_fn=<AddBackward0>)\n",
      "tensor(0.6645, grad_fn=<AddBackward0>)\n",
      "tensor(0.6111, grad_fn=<AddBackward0>)\n",
      "tensor(0.6318, grad_fn=<AddBackward0>)\n",
      "tensor(0.5988, grad_fn=<AddBackward0>)\n",
      "tensor(0.6095, grad_fn=<AddBackward0>)\n",
      "tensor(0.5998, grad_fn=<AddBackward0>)\n",
      "tensor(0.5902, grad_fn=<AddBackward0>)\n",
      "tensor(0.6232, grad_fn=<AddBackward0>)\n",
      "tensor(0.6101, grad_fn=<AddBackward0>)\n",
      "tensor(0.6019, grad_fn=<AddBackward0>)\n",
      "tensor(0.6134, grad_fn=<AddBackward0>)\n",
      "tensor(0.5921, grad_fn=<AddBackward0>)\n",
      "tensor(0.5711, grad_fn=<AddBackward0>)\n",
      "tensor(0.5408, grad_fn=<AddBackward0>)\n",
      "tensor(0.6138, grad_fn=<AddBackward0>)\n",
      "tensor(0.5519, grad_fn=<AddBackward0>)\n",
      "tensor(0.5817, grad_fn=<AddBackward0>)\n",
      "tensor(0.5524, grad_fn=<AddBackward0>)\n",
      "tensor(0.6330, grad_fn=<AddBackward0>)\n",
      "tensor(0.5552, grad_fn=<AddBackward0>)\n",
      "tensor(0.5366, grad_fn=<AddBackward0>)\n",
      "tensor(0.5860, grad_fn=<AddBackward0>)\n",
      "tensor(0.5698, grad_fn=<AddBackward0>)\n",
      "tensor(0.5620, grad_fn=<AddBackward0>)\n",
      "tensor(0.5714, grad_fn=<AddBackward0>)\n",
      "tensor(0.5381, grad_fn=<AddBackward0>)\n",
      "tensor(0.5062, grad_fn=<AddBackward0>)\n",
      "tensor(0.5899, grad_fn=<AddBackward0>)\n",
      "tensor(0.5344, grad_fn=<AddBackward0>)\n",
      "tensor(0.4957, grad_fn=<AddBackward0>)\n",
      "tensor(0.4623, grad_fn=<AddBackward0>)\n",
      "tensor(0.5341, grad_fn=<AddBackward0>)\n",
      "tensor(0.4601, grad_fn=<AddBackward0>)\n",
      "tensor(0.5552, grad_fn=<AddBackward0>)\n",
      "tensor(0.5634, grad_fn=<AddBackward0>)\n",
      "tensor(0.5844, grad_fn=<AddBackward0>)\n",
      "tensor(0.4839, grad_fn=<AddBackward0>)\n",
      "tensor(0.5158, grad_fn=<AddBackward0>)\n",
      "tensor(0.5485, grad_fn=<AddBackward0>)\n",
      "tensor(0.4595, grad_fn=<AddBackward0>)\n",
      "tensor(0.5656, grad_fn=<AddBackward0>)\n",
      "tensor(0.5566, grad_fn=<AddBackward0>)\n",
      "tensor(0.5400, grad_fn=<AddBackward0>)\n",
      "tensor(0.5150, grad_fn=<AddBackward0>)\n",
      "tensor(0.4322, grad_fn=<AddBackward0>)\n",
      "tensor(0.5164, grad_fn=<AddBackward0>)\n",
      "tensor(0.5351, grad_fn=<AddBackward0>)\n",
      "tensor(0.4982, grad_fn=<AddBackward0>)\n",
      "tensor(0.4532, grad_fn=<AddBackward0>)\n",
      "tensor(0.4724, grad_fn=<AddBackward0>)\n",
      "tensor(0.5374, grad_fn=<AddBackward0>)\n",
      "tensor(0.4395, grad_fn=<AddBackward0>)\n",
      "tensor(0.4123, grad_fn=<AddBackward0>)\n",
      "tensor(0.4546, grad_fn=<AddBackward0>)\n",
      "tensor(0.4619, grad_fn=<AddBackward0>)\n",
      "tensor(0.5047, grad_fn=<AddBackward0>)\n",
      "tensor(0.4684, grad_fn=<AddBackward0>)\n",
      "tensor(0.4609, grad_fn=<AddBackward0>)\n",
      "tensor(0.4927, grad_fn=<AddBackward0>)\n",
      "tensor(0.4587, grad_fn=<AddBackward0>)\n",
      "tensor(0.4476, grad_fn=<AddBackward0>)\n",
      "tensor(0.4552, grad_fn=<AddBackward0>)\n",
      "tensor(0.4825, grad_fn=<AddBackward0>)\n",
      "tensor(0.4815, grad_fn=<AddBackward0>)\n",
      "tensor(0.4438, grad_fn=<AddBackward0>)\n",
      "tensor(0.3908, grad_fn=<AddBackward0>)\n",
      "tensor(0.4818, grad_fn=<AddBackward0>)\n",
      "tensor(0.4757, grad_fn=<AddBackward0>)\n",
      "tensor(0.4539, grad_fn=<AddBackward0>)\n",
      "tensor(0.4580, grad_fn=<AddBackward0>)\n",
      "tensor(0.4814, grad_fn=<AddBackward0>)\n",
      "tensor(0.4558, grad_fn=<AddBackward0>)\n",
      "tensor(0.4842, grad_fn=<AddBackward0>)\n",
      "tensor(0.4071, grad_fn=<AddBackward0>)\n",
      "tensor(0.5165, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     46\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 48\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "#s_labels is a vector with batch_size labels (0-9) for a minibatch of SVHN digits\n",
    "#m_labels is a vector with batch_size labels (0-9) for a minibatch of MNIST digits \n",
    "iterations = 1000\n",
    "train_losses = [] # use to append the avg loss for each minibatch \n",
    "triplet_loss = nn.TripletMarginLoss(margin=0.2)\n",
    "for i in range(iterations):\n",
    "  svhn_iter = iter(train_svhn)\n",
    "  for m_data, m_labels in train_mnist:\n",
    "    s_data, s_labels = next(svhn_iter)\n",
    "    s_data\n",
    "    s_labels\n",
    "    m_data\n",
    "    m_labels\n",
    "\n",
    "    label_set_m = range(0,10)\n",
    "    label_to_indices_m = {label: np.where(s_labels.cpu().numpy() == label)[0] for label in label_set_m}\n",
    "    idx_pos_m = []\n",
    "    idx_neg_m = []\n",
    "    for lab in m_labels:\n",
    "      positive_index_m = np.random.choice(label_to_indices_m[lab.item()])\n",
    "      negative_label_m = np.random.choice(list(set(label_set_m) - set([lab.item()])))\n",
    "      negative_index_m = np.random.choice(label_to_indices_m[negative_label_m])\n",
    "\n",
    "      idx_pos_m.append(positive_index_m)\n",
    "      idx_neg_m.append(negative_index_m)\n",
    "    #idx_pos and idx_neg can now can now be used to index the MNIST data minibatch to give positives and negatives\n",
    "\n",
    "    label_set_s = range(0,10)\n",
    "    label_to_indices_s = {label: np.where(m_labels.cpu().numpy() == label)[0] for label in label_set_s}\n",
    "    idx_pos_s = []\n",
    "    idx_neg_s = []\n",
    "    for lab in s_labels:\n",
    "      positive_index_s = np.random.choice(label_to_indices_s[lab.item()])\n",
    "      negative_label_s = np.random.choice(list(set(label_set_s) - set([lab.item()])))\n",
    "      negative_index_s = np.random.choice(label_to_indices_s[negative_label_s])\n",
    "\n",
    "      idx_pos_s.append(positive_index_s)\n",
    "      idx_neg_s.append(negative_index_s)\n",
    "\n",
    "    output1 = model_mnist(m_data)\n",
    "    output2 = model_svhn(s_data)\n",
    "\n",
    "    loss = triplet_loss(output1, model_svhn(s_data[idx_pos_m]), model_svhn(s_data[idx_neg_m])) + triplet_loss(output2, model_mnist(m_data[idx_pos_s]), model_mnist(m_data[idx_neg_s]))\n",
    "    train_losses.append(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e9dda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
